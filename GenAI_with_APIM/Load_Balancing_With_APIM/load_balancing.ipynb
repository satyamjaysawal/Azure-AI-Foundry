{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c0c95",
   "metadata": {},
   "source": [
    "## Multi-Region Load Balancing with Azure API Management (APIM)\n",
    "\n",
    "Multi-region load balancing with Azure API Management (APIM) enables high availability, improved performance, and disaster recovery for your APIs by distributing traffic across multiple Azure regions.\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "- **High Availability:** Ensures your APIs remain accessible even if one region experiences an outage.\n",
    "- **Performance Optimization:** Routes client requests to the healthiest region, reducing latency.\n",
    "- **Disaster Recovery:** Provides failover capabilities in case of regional failures.\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "1. **Circuit Breaker Pattern:** Use Load Balancer with Circuit Breaker Pattern.\n",
    "2. **Backend Services:** Ensure backend APIs are also deployed in multiple regions or are accessible from all APIM instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebde5a4",
   "metadata": {},
   "source": [
    "![backend-pool-load-balancing.gif](backend-pool-load-balancing.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805e9af",
   "metadata": {},
   "source": [
    "### 0Ô∏è‚É£ Initialize notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "apim_endpoint = os.getenv(\"APIM_ENDPOINT\")\n",
    "apim_subscription_key = os.getenv(\"APIM_SUBSCRIPTION_KEY\")\n",
    "apim_gateway_url = os.getenv(\"APIM_GATEWAY_URL\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "api_version = os.getenv(\"OPENAI_API_VERSION\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33da539",
   "metadata": {},
   "source": [
    "### üß™ Test the API using a direct HTTP call\n",
    "\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses.\n",
    "\n",
    "You will not see HTTP 429s returned as API Management's retry policy will select an available backend. If no backends are viable, an HTTP 503 will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "import utils\n",
    "import json\n",
    "\n",
    "runs=5\n",
    "sleep_time_ms = 100\n",
    "url = apim_endpoint\n",
    "\n",
    "messages = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I am going to Paris, what should I see?\"\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 1500,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1,\n",
    "        \"model\": f\"{model_deployment_name}\"\n",
    "    }\n",
    "\n",
    "api_runs = []\n",
    "\n",
    "# Initialize a session for connection pooling and set any default headers\n",
    "session = requests.Session()\n",
    "session.headers.update({'api-key': apim_subscription_key})\n",
    "\n",
    "try:\n",
    "    for i in range(runs):\n",
    "        print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = session.post(url, json = messages)\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"‚åö {response_time:.2f} seconds\")\n",
    "\n",
    "        print(f\"Response code: {response.status_code}\")\n",
    "\n",
    "      \n",
    "        if \"x-ms-region\" in response.headers:\n",
    "            print(f\"x-ms-region: \\x1b[1;32m{response.headers.get('x-ms-region')}\\x1b[0m\")  # this header is useful to determine the region of the backend that served the request\n",
    "            api_runs.append((response_time, response.headers.get('x-ms-region')))\n",
    "\n",
    "\n",
    "        if (response.status_code == 200):\n",
    "            data = json.loads(response.text)\n",
    "            print(f\"Token usage: {json.dumps(dict(data.get('usage')), indent = 4)}\\n\")\n",
    "            print(f\"üí¨ {data.get('choices')[0].get('message').get('content')}\\n\")\n",
    "        else:\n",
    "            print(f\"{response.text}\\n\")\n",
    "\n",
    "        time.sleep(sleep_time_ms/1000)\n",
    "finally:\n",
    "    # Close the session to release the connection\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615d558",
   "metadata": {},
   "source": [
    "### üîç Analyze Load Balancing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle as pltRectangle\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns = ['Response Time', 'Region'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "\n",
    "# Define a color map for each region\n",
    "color_map = {'East US': 'lightpink', 'Sweden Central': 'lightyellow'}  # Add more regions and colors as needed\n",
    "\n",
    "# Plot the dataframe with colored bars\n",
    "ax = df.plot(kind = 'bar', x = 'Run', y = 'Response Time', color = [color_map.get(region, 'gray') for region in df['Region']], legend = False)\n",
    "\n",
    "# Add legend\n",
    "legend_labels = [pltRectangle((0, 0), 1, 1, color = color_map.get(region, 'gray')) for region in df['Region'].unique()]\n",
    "ax.legend(legend_labels, df['Region'].unique())\n",
    "\n",
    "plt.title('Load Balancing results')\n",
    "plt.xlabel('Run #')\n",
    "plt.ylabel('Response Time')\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "average = df['Response Time'].mean()\n",
    "plt.axhline(y = average, color = 'r', linestyle = '--', label = f'Average: {average:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2b81d",
   "metadata": {},
   "source": [
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility. Note that we do not know what region served the response; we only see that we obtained a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 5\n",
    "sleep_time_ms = 100\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = apim_gateway_url,\n",
    "    api_key = apim_subscription_key,\n",
    "    api_version = api_version\n",
    ")\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    raw_response = client.chat.completions.with_raw_response.create(\n",
    "        messages = [\n",
    "             {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I am going to Paris, what should I see?\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens= 1500,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        model = model_deployment_name\n",
    "        )\n",
    "    response_time = time.time() - start_time\n",
    "\n",
    "    print(f\"‚åö {response_time:.2f} seconds\")\n",
    "    print(f\"x-ms-region: \\x1b[1;32m{raw_response.headers.get('x-ms-region')}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "\n",
    "    response = raw_response.parse()\n",
    "\n",
    "    if response.usage:\n",
    "        print(f\"Token usage:\\n   Total tokens: {response.usage.total_tokens}\\n   Prompt tokens: {response.usage.prompt_tokens}\\n   Completion tokens: {response.usage.completion_tokens}\\n\")\n",
    "\n",
    "    print(f\"üí¨ {response.choices[0].message.content}\\n\")\n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
